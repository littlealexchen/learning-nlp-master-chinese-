{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['南京市', '长江大桥']\n"
     ]
    }
   ],
   "source": [
    "#逆向最大匹配\n",
    "class IMM(object):\n",
    "    def __init__(self, dic_path):\n",
    "        self.dictionary = set()\n",
    "        self.maximum = 0\n",
    "        #读取词典\n",
    "        with open(dic_path, 'r', encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                self.dictionary.add(line)\n",
    "                if len(line) > self.maximum:\n",
    "                    self.maximum = len(line)\n",
    "    def cut(self, text):\n",
    "        result = []\n",
    "        index = len(text)\n",
    "        while index > 0:\n",
    "            word = None\n",
    "            for size in range(self.maximum, 0, -1):\n",
    "                if index - size < 0:\n",
    "                    continue\n",
    "                piece = text[(index - size):index]\n",
    "                if piece in self.dictionary:\n",
    "                    word = piece\n",
    "                    result.append(word)\n",
    "                    index -= size\n",
    "                    break+\n",
    "            if word is None:\n",
    "                index -= 1\n",
    "        return result[::-1]\n",
    "\n",
    "def main():\n",
    "    text = \"南京市长江大桥\"\n",
    "    \n",
    "    tokenizer = IMM('./data/imm_dic.utf8')\n",
    "    print(tokenizer.cut(text))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['南京市长', '大桥']\n"
     ]
    }
   ],
   "source": [
    "#正向最大匹配\n",
    "class IMM(object):\n",
    "    def __init__(self, dic_path):\n",
    "        self.dictionary = set()\n",
    "        self.maximum = 0\n",
    "        #读取词典\n",
    "        with open(dic_path, 'r', encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                self.dictionary.add(line)\n",
    "                if len(line) > self.maximum:\n",
    "                    self.maximum = len(line)\n",
    "    def cut(self, text):\n",
    "        result = []\n",
    "        index = 0\n",
    "        while index < len(text):\n",
    "            word = None\n",
    "            for size in range(self.maximum, 0, -1):\n",
    "                if len(text) - index < size:\n",
    "                    continue\n",
    "                piece = text[index: (index + size)]\n",
    "                if piece in self.dictionary:\n",
    "                    word = piece\n",
    "                    result.append(word)\n",
    "                    index += size\n",
    "                    break\n",
    "            if word is None:\n",
    "                index += 1\n",
    "        return result\n",
    "\n",
    "def main():\n",
    "    text = \"南京市长江大桥\"\n",
    "    \n",
    "    tokenizer = IMM('./data/imm_dic.utf8')\n",
    "    print(tokenizer.cut(text))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    def __init__(self):\n",
    "        import os\n",
    "        \n",
    "        # 主要是用于存取算法中间结果，不用每次都训练模型\n",
    "        self.model_file = './data/hmm_model.pkl'\n",
    "        \n",
    "        # 状态值集合\n",
    "        self.state_list = ['B','M', 'E', 'S']\n",
    "        \n",
    "        # 参数加载，用于判断是否需要重新加载model_file\n",
    "        self.load_para = False\n",
    "    \n",
    "    # 用于加载已计算的中间结果，当需要重新训练时，需初始化清空结果\n",
    "    def try_load_model(self, trained):\n",
    "        if trained:\n",
    "            import pickle\n",
    "            with open(self.model_file, 'rb') as f:\n",
    "                self.A_dic = pickle.load(f)\n",
    "                self.B_dic = pickle.load(f)\n",
    "                self.Pi_dic = pickle.load(f)\n",
    "                self.load_para = True\n",
    "        else:\n",
    "            # 状态转移概率（状态->状态的条件概率）\n",
    "            self.A_dic = {}\n",
    "            # 发射概率（状态->词语的条件概率）\n",
    "            self.B_dic = {}\n",
    "            # 状态的初始概率\n",
    "            self.Pi_dic = {}\n",
    "            self.load_para = False\n",
    "    \n",
    "    # 技术按转移概率、发射概率以及初始概率\n",
    "    def train(self, path):\n",
    "        \n",
    "        # 重置几个概率矩阵\n",
    "        self.try_load_model(False)\n",
    "        \n",
    "        # 统计状态出现次数，求p(o)\n",
    "        Count_dic = {}\n",
    "        \n",
    "        # 初始化参数\n",
    "        def init_parameters():\n",
    "            for state in self.state_list:\n",
    "                self.A_dic[state] = {s: 0.0 for s in self.state_list}\n",
    "                self.Pi_dic[state] = 0.0\n",
    "                self.B_dic[state] = {}\n",
    "                Count_dic[state] = 0\n",
    "        \n",
    "        def makeLabel(text):\n",
    "            out_text = []\n",
    "            if len(text) == 1:\n",
    "                out_text.append('S')\n",
    "            else:\n",
    "                out_text += ['B'] + ['M']*(len(text) -2) + ['E']\n",
    "            \n",
    "            return out_text\n",
    "        \n",
    "        init_parameters()\n",
    "        line_num = -1\n",
    "        # 观察者集合，主要是字以及标点等\n",
    "        words = set()\n",
    "        with open(path, encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                # AJ注：在文件中一行的例子为'十亿 中华 儿女 踏上 新 的 征 程 。 '\n",
    "                line_num += 1\n",
    "                \n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                word_list = [i for i in line if i != ' '] # AJ注：一行包括哪些字\n",
    "                words |= set(word_list) # 更新字的集合\n",
    "                \n",
    "                linelist = line.split()\n",
    "                line_state = [] # AJ注：一行标注的结果\n",
    "                for w in linelist:\n",
    "                    line_state.extend(makeLabel(w))\n",
    "                        \n",
    "                assert len(word_list) == len(line_state)\n",
    "                \n",
    "                for k, v in enumerate(line_state):\n",
    "                    Count_dic[v] += 1\n",
    "                    if k == 0:\n",
    "                        self.Pi_dic[v] += 1 # 每个句子的第一个字的状态，用于计算初始状态概率\n",
    "                    else:\n",
    "                        self.A_dic[line_state[k-1]][v] += 1 # 计算转移概率\n",
    "                        self.B_dic[line_state[k]][word_list[k]] = \\\n",
    "                              self.B_dic[line_state[k]].get(word_list[k], 0) + 1.0 # 计算发射概率\n",
    "        print('self.pi_dic.items', self.Pi_dic.items())\n",
    "        self.Pi_dic = {k: v * 1.0 / line_num for k, v in self.Pi_dic.items()}\n",
    "        self.A_dic = {k: {k1: v1 / Count_dic[k] for k1, v1 in v.items()}\n",
    "                      for k, v in self.A_dic.items()}\n",
    "        self.B_dic = {k: {k1: (v1 + 1) / Count_dic[k] for k1, v1 in v.items()}\n",
    "                      for k, v in self.B_dic.items()}\n",
    "        \n",
    "        import pickle\n",
    "        with open(self.model_file, 'wb') as f:\n",
    "            pickle.dump(self.A_dic, f)\n",
    "            pickle.dump(self.B_dic, f)\n",
    "            pickle.dump(self.Pi_dic, f)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def viterbi(self, text, states, start_p, trans_p, emit_p):\n",
    "        V = [{}]\n",
    "        path = {}\n",
    "        for y in states:\n",
    "            V[0][y] = start_p[y] * emit_p[y].get(text[0], 0)\n",
    "            path[y] = [y]\n",
    "        for t in range(1, len(text)):\n",
    "            V.append({})\n",
    "            newpath = {}\n",
    "            \n",
    "            #检验训练的发射概率矩阵中是否有该字\n",
    "            neverSeen = text[t] not in emit_p['S'].keys() and \\\n",
    "                text[t] not in emit_p['M'].keys() and \\\n",
    "                text[t] not in emit_p['E'].keys() and \\\n",
    "                text[t] not in emit_p['B'].keys()\n",
    "            for y in states:\n",
    "                emitP = emit_p[y].get(text[t], 0) if not neverSeen else 1.0 #设置未知字单独成词\n",
    "                (prob, state) = max(\n",
    "                [(V[t-1][y0] * trans_p[y0].get(y, 0) * emitP, y0)\n",
    "                for y0 in states if V[t - 1][y0] > 0])\n",
    "                V[t][y] = prob\n",
    "                newpath[y] = path[state] + [y]\n",
    "            path = newpath\n",
    "        \n",
    "        if emit_p['M'].get(text[-1], 0) > emit_p['S'].get(text[-1], 0):\n",
    "            (prob, state) = max([(V[len(text) - 1][y], y) for y in ('E','M')])\n",
    "        else:\n",
    "            (prob, state) = max([(V[len(text) - 1][y], y) for y in states])\n",
    "                    \n",
    "        return (prob, path[state])\n",
    "    \n",
    "    def cut(self, text):\n",
    "        import os\n",
    "        if not self.load_para:\n",
    "            self.try_load_model(os.path.exists(self.model_file))\n",
    "        prob, pos_list = self.viterbi(text, self.state_list, self.Pi_dic, self.A_dic, self.B_dic)      \n",
    "        begin, next = 0, 0\n",
    "        for i, char in enumerate(text):\n",
    "            pos = pos_list[i]\n",
    "            if pos == 'B':\n",
    "                begin = i\n",
    "            elif pos == 'E':\n",
    "                yield text[begin: i+1]\n",
    "                next = i+1\n",
    "            elif pos == 'S':\n",
    "                yield char\n",
    "                next = i+1\n",
    "        if next < len(text):\n",
    "            yield text[next:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.pi_dic.items dict_items([('B', 173416.0), ('M', 0.0), ('E', 0.0), ('S', 124543.0)])\n",
      "这是一个非常棒的方案！\n",
      "['这是', '一个', '非常', '棒', '的', '方案', '！']\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM()\n",
    "hmm.train('./data/trainCorpus.txt_utf8')\n",
    "\n",
    "text = '这是一个非常棒的方案！'\n",
    "res = hmm.cut(text)\n",
    "print(text)\n",
    "print(str(list(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AJ: 测试一些东西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['十亿', '中华', '儿女', '踏上', '新', '的', '征', '程', '。']\n"
     ]
    }
   ],
   "source": [
    "string = '十亿 中华 儿女 踏上 新 的 征 程 。 '\n",
    "print(string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S': {'S': 0.46460125869921165, 'M': 0.0, 'B': 0.3503213832274479, 'E': 0.0}, 'M': {'S': 0.0, 'M': 0.2777743117140081, 'B': 0.0, 'E': 0.7222256882859919}, 'B': {'S': 0.0, 'M': 0.1167175117318146, 'B': 0.0, 'E': 0.8832824882681853}, 'E': {'S': 0.5310673430644739, 'M': 0.0, 'B': 0.46893265693552616, 'E': 0.0}}\n",
      "----------------------------\n",
      "----------------------------\n",
      "{'S': 0.41798844132394497, 'M': 0.0, 'B': 0.5820149148537713, 'E': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./data/hmm_model.pkl', 'rb') as f:\n",
    "    dt1 = pickle.load(f)\n",
    "    print(dt1)\n",
    "    print('----------------------------')\n",
    "    dt2 = pickle.load(f)\n",
    "#     print(dt2[:50])\n",
    "    print('----------------------------')\n",
    "    dt3 = pickle.load(f)\n",
    "    print(dt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\47849\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.031 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本之一：新华网香港4月27日电 李嘉诚基金会已累计捐款1．1亿元人民币在内地推广“宁养服务计划”，关怀晚期癌症患者，目前已服务病人4万余人，累计出诊达到42．7万次。据香港媒体报道，汕头大学副校长兼医学院院长李玉光介绍说，1998年3月与李嘉诚在香港谈及如何解决晚期癌症患者问题，初步酝酿了相关计划。同年11月在汕头大学医学院第一附属医院成立了第一个专业机构，由李嘉诚亲自定名为“宁养院”。李玉光说，“宁养院”确定了“贫困、癌症、家居、免费”的八字方针，表明“宁养院”的服务对象是贫困的癌症病人；服务方式是免费登门服务，有别于住院治疗；服务内容包括药物止痛、心理辅导，帮助病人减轻疼痛折磨，树立尊严。李嘉诚基金会罗敏洁医生说，有感于一所“宁养院”的服务范围太小，从2001年1月起，基金会开始在内地实施“宁养服务计划”，5年间已经将“宁养院”扩展到20家，覆盖了内地130个区县。每个“宁养院”的服务半径为300公里，每年由李嘉诚基金会拨付120万元人民币。到目前为止，该计划已服务病人4万多人，累计出诊达42．7万次。（完）\n",
      "样本分词效果： 新华网/ 香港/ 4/ 月/ 27/ 日电/  / 李嘉诚基金会/ 已/ 累计/ 捐款/ 1/ ．/ 1/ 亿元/ 人民币/ 在/ 内地/ 推广/ “/ 宁养/ 服务/ 计划/ ”/ ，/ 关怀/ 晚期/ 癌症/ 患者/ ，/ 目前/ 已/ 服务/ 病人/ 4/ 万余/ 人/ ，/ 累计/ 出诊/ 达到/ 42/ ．/ 7/ 万次/ 。/ 据/ 香港媒体/ 报道/ ，/ 汕头大学/ 副校长/ 兼/ 医学院/ 院长/ 李玉光/ 介绍/ 说/ ，/ 1998/ 年/ 3/ 月/ 与/ 李嘉诚/ 在/ 香港/ 谈及/ 如何/ 解决/ 晚期/ 癌症/ 患者/ 问题/ ，/ 初步/ 酝酿/ 了/ 相关/ 计划/ 。/ 同年/ 11/ 月/ 在/ 汕头大学/ 医学院/ 第一/ 附属/ 医院/ 成立/ 了/ 第一个/ 专业/ 机构/ ，/ 由/ 李嘉诚/ 亲自/ 定名/ 为/ “/ 宁养院/ ”/ 。/ 李玉光/ 说/ ，/ “/ 宁养院/ ”/ 确定/ 了/ “/ 贫困/ 、/ 癌症/ 、/ 家居/ 、/ 免费/ ”/ 的/ 八字/ 方针/ ，/ 表明/ “/ 宁养院/ ”/ 的/ 服务/ 对象/ 是/ 贫困/ 的/ 癌症病人/ ；/ 服务/ 方式/ 是/ 免费/ 登门/ 服务/ ，/ 有别于/ 住院治疗/ ；/ 服务/ 内容/ 包括/ 药物/ 止痛/ 、/ 心理/ 辅导/ ，/ 帮助/ 病人/ 减轻/ 疼痛/ 折磨/ ，/ 树立/ 尊严/ 。/ 李嘉诚基金会/ 罗敏洁/ 医生/ 说/ ，/ 有感于/ 一所/ “/ 宁养院/ ”/ 的/ 服务/ 范围/ 太小/ ，/ 从/ 2001/ 年/ 1/ 月/ 起/ ，/ 基金会/ 开始/ 在/ 内地/ 实施/ “/ 宁养/ 服务/ 计划/ ”/ ，/ 5/ 年间/ 已经/ 将/ “/ 宁养院/ ”/ 扩展/ 到/ 20/ 家/ ，/ 覆盖/ 了/ 内地/ 130/ 个/ 区县/ 。/ 每个/ “/ 宁养院/ ”/ 的/ 服务半径/ 为/ 300/ 公里/ ，/ 每年/ 由/ 李嘉诚基金会/ 拨付/ 120/ 万元/ 人民币/ 。/ 到/ 目前为止/ ，/ 该/ 计划/ 已/ 服务/ 病人/ 4/ 万多/ 人/ ，/ 累计/ 出诊/ 达/ 42/ ．/ 7/ 万次/ 。/ （/ 完/ ）\n",
      "样本top10词： [('，', 20), ('“', 9), ('服务', 9), ('”', 9), ('。', 7), ('宁养院', 6), ('的', 5), ('月', 4), ('在', 4), ('计划', 4)]\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "def get_content(path):\n",
    "    \n",
    "    with open(path, 'r', encoding='gbk', errors='ignore') as f:\n",
    "        content = ''\n",
    "        for l in f:\n",
    "            l = l.strip()\n",
    "            content += l\n",
    "    return content\n",
    "\n",
    "# 定义高频词统计的函数\n",
    "def get_TF(words, topK=10):\n",
    "    tf_dic = {}\n",
    "    for w in words:\n",
    "        tf_dic[w] = tf_dic.get(w, 0) + 1\n",
    "    return sorted(tf_dic.items(), key = lambda x: x[1], reverse=True)[:topK]\n",
    "\n",
    "def main():\n",
    "    import glob\n",
    "    import random\n",
    "    import jieba\n",
    "    \n",
    "    files = glob.glob('./data/news/C000013/*.txt')\n",
    "    corpus = [get_content(x) for x in files]\n",
    "    \n",
    "    sample_inx = random.randint(0, len(corpus))\n",
    "    split_words = list(jieba.cut(corpus[sample_inx]))\n",
    "    print('样本之一：' + corpus[sample_inx])\n",
    "    print('样本分词效果： '+ '/ '.join(split_words))\n",
    "    print('样本top10词： '+ str(get_TF(split_words)))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本之一：慢性肾病易被忽视52岁的张女士，5年前因头晕去医院检查发现血压偏高，由于症状不明显，未引起足够重视。半年前，张女士在劳累后出现全身浮肿的现象，经检查发现血压高达180/100毫米汞柱，再到肾病专科就诊，B超检测显示肾脏已经萎缩，医生诊断为晚期肾病。虽经多方治疗但无明显效果，最终转为尿毒症。很多患者像张女士一样，初次到肾病专科就诊就被确诊为晚期肾病。据统计，有近1/3的患者在就诊时不知道已患有肾病，大多是因为出现心衰、贫血、消化道出血、感染等症状去医院检查时才查出尿毒症。这是因为肾脏有很强的解毒功能，当身体出现各种症状时，肾脏已出现严重损伤。此外，还有相当一部分早期肾病患者，由于讳疾忌医，不愿意进行彻底治疗，错过最佳治疗时间，导致了尿毒症。有资料显示，我国40岁以上的人肾病发病率约为8%%－9%%，每100万人口中有100人患有尿毒症，需要终生透析治疗，治疗费用是普通家庭难以承受的。体检可查出肾病除了从身体里清除废物和液体，肾脏还有其他重要功能：调节身体的水分和血液中的钠、钾、磷和钙等化学物质；清除摄入体内的药物和毒物；调节和生成血液中的激素；调节血压；生成红细胞；构建强壮的骨骼。肾脏功能受损时，废物会在血液里堆积到很高的水平而使您感觉不适，还会导致高血压(专题 访谈 咨询)、贫血、骨质脆弱、营养不良以及神经损伤等症状。肾病还会增加患心血管疾病的危险。大部分患者在疾病很严重之前不会有任何严重的症状。如果有下列症状就要引起注意：感觉乏力，精力不充沛；注意力难以集中；食欲下降；睡眠障碍；夜间抽筋；脚和踝部浮肿；眼周水肿，特别是早晨；皮肤干燥、痒；尿频，特别是夜间。除了要注意这些症状外，每年最好体检一次，尿检的一些指标可以反应肾脏的状况。学会呵护肾脏引起慢性肾病的原因主要有：肾炎，肾脏炎症会影响功能；糖尿病，血糖过高会损害身体内的许多器官，包括肾脏和心脏，还有血管、神经和眼睛；高血压，当血液对血管的压力增加时，如果不加控制或控制不良，就会引起心脏病、中风和肾脏疾病；胎儿在母亲体内发育畸形，如输尿管狭窄而阻碍尿液的正常流出，引起尿液返流到肾脏，引起感染而损伤肾脏；红斑狼疮及其他影响人体免疫系统的疾病；由肾结石、肿瘤(专题 访谈 咨询)或男性增大的前列腺而引起的尿路梗阻；反复的泌尿系统感染。预防肾病要对可能引起肾病的各种高风险因素如糖尿病、高血压病、高血脂等疾病进行及时有效的治疗或控制。对已有的肾脏疾病如肾小球肾炎进行治疗。对于已有的轻、中度慢性肾病，不仅要积极控制某些影响病情进展的因素，而且要避免可能导致病情加剧的危险因素，延缓慢性肾病的进展。\n",
      "样本分词效果： 慢性/ 肾病/ 易/ 被忽视/ 52/ 岁/ 张女士/ 年前/ 头晕/ 医院/ 检查/ 发现/ 血压/ 偏高/ 症状/ 明显/ 未/ 引起/ 足够/ 重视/ 半年前/ 张女士/ 劳累/ 出现/ 全身/ 浮肿/ 现象/ 检查/ 发现/ 血压高/ 达/ 180/ 100/ 毫米汞柱/ 肾病/ 专科/ 就诊/ B超/ 检测/ 显示/ 肾脏/ 已经/ 萎缩/ 医生/ 诊断/ 晚期/ 肾病/ 虽经/ 多方/ 治疗/ 明显/ 效果/ 最终/ 转为/ 尿毒症/ 很多/ 患者/ 张女士/ 初次/ 肾病/ 专科/ 就诊/ 确诊/ 晚期/ 肾病/ 据统计/ 有近/ 患者/ 就诊/ 时/ 知道/ 患有/ 肾病/ 大多/ 是因为/ 出现/ 心衰/ 贫血/ 消化道/ 出血/ 感染/ 症状/ 医院/ 检查/ 时才/ 查出/ 尿毒症/ 是因为/ 肾脏/ 强/ 解毒/ 功能/ 身体/ 出现/ 症状/ 时/ 肾脏/ 出现/ 严重/ 损伤/ 相当/ 一部分/ 早期/ 肾病/ 患者/ 讳疾忌医/ 愿意/ 进行/ 彻底/ 治疗/ 错过/ 最佳/ 治疗/ 时间/ 导致/ 尿毒症/ 资料/ 显示/ 我国/ 40/ 岁/ 肾病/ 发病率/ 约/ 8%/ －/ 9%/ 100/ 万/ 人口/ 中有/ 100/ 患有/ 尿毒症/ 需要/ 终生/ 透析/ 治疗/ 治疗/ 费用/ 普通家庭/ 难以承受/ 体检/ 查出/ 肾病/ 身体/ 里/ 清除/ 废物/ 液体/ 肾脏/ 重要/ 功能/ 调节/ 身体/ 水分/ 血液/ 中/ 钠/ 钾/ 磷/ 钙/ 化学物质/ 清除/ 摄入/ 体内/ 药物/ 毒物/ 调节/ 生成/ 血液/ 中/ 激素/ 调节/ 血压/ 生成/ 红细胞/ 构建/ 强壮/ 骨骼/ 肾脏/ 功能/ 受损/ 时/ 废物/ 会/ 血液/ 里/ 堆积/ 高/ 水平/ 感觉/ 不适/ 还会/ 导致/ 高血压/ 专题/  / 访谈/  / 咨询/ 贫血/ 骨质/ 脆弱/ 营养不良/ 神经/ 损伤/ 症状/ 肾病/ 还会/ 增加/ 患/ 心血管/ 疾病/ 危险/ 大部分/ 患者/ 疾病/ 严重/ 之前/ 不会/ 严重/ 症状/ 下列/ 症状/ 引起/ 注意/ 感觉/ 乏力/ 精力/ 充沛/ 注意力/ 难以/ 集中/ 食欲/ 下降/ 睡眠/ 障碍/ 夜间/ 抽筋/ 脚/ 踝部/ 浮肿/ 眼周/ 水肿/ 特别/ 早晨/ 皮肤/ 干燥/ 痒/ 尿频/ 特别/ 夜间/ 注意/ 症状/ 外/ 每年/ 最好/ 体检/ 一次/ 尿检/ 指标/ 反应/ 肾脏/ 状况/ 学会/ 呵护/ 肾脏/ 引起/ 慢性/ 肾病/ 原因/ 主要/ 肾炎/ 肾脏/ 炎症/ 会/ 影响/ 功能/ 糖尿病/ 血糖/ 过高会/ 损害/ 身体/ 器官/ 包括/ 肾脏/ 心脏/ 血管/ 神经/ 眼睛/ 高血压/ 血液/ 血管/ 压力/ 增加/ 时/ 加/ 控制/ 控制/ 不良/ 会/ 引起/ 心脏病/ 中风/ 肾脏/ 疾病/ 胎儿/ 母亲/ 体内/ 发育畸形/ 输尿管/ 狭窄/ 阻碍/ 尿液/ 正常/ 流出/ 引起/ 尿液/ 返流/ 肾脏/ 引起/ 感染/ 损伤/ 肾脏/ 红斑狼疮/ 影响/ 人体/ 免疫系统/ 疾病/ 肾结石/ 肿瘤/ 专题/  / 访谈/  / 咨询/ 男性/ 增大/ 前列腺/ 引起/ 尿路/ 梗阻/ 反复/ 泌尿系统/ 感染/ 预防/ 肾病/ 可能/ 引起/ 肾病/ 高风险/ 因素/ 糖尿病/ 高血压病/ 高血脂/ 疾病/ 进行/ 及时/ 有效/ 治疗/ 控制/ 已有/ 肾脏/ 疾病/ 肾小球/ 肾炎/ 进行/ 治疗/ 已有/ 轻/ 中度/ 慢性/ 肾病/ 积极/ 控制/ 影响/ 病情/ 进展/ 因素/ 避免/ 可能/ 导致/ 病情/ 加剧/ 危险/ 因素/ 延缓/ 慢性/ 肾病/ 进展\n",
      "样本top10词： [('肾病', 15), ('肾脏', 13), ('引起', 8), ('症状', 7), ('治疗', 7), ('疾病', 6), ('慢性', 4), ('出现', 4), ('尿毒症', 4), ('患者', 4)]\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "def get_content(path):\n",
    "    \n",
    "    with open(path, 'r', encoding='gbk', errors='ignore') as f:\n",
    "        content = ''\n",
    "        for l in f:\n",
    "            l = l.strip()\n",
    "            content += l\n",
    "    return content\n",
    "\n",
    "# 定义高频词统计的函数\n",
    "def get_TF(words, topK=10):\n",
    "    tf_dic = {}\n",
    "    for w in words:\n",
    "        tf_dic[w] = tf_dic.get(w, 0) + 1\n",
    "    return sorted(tf_dic.items(), key = lambda x: x[1], reverse=True)[:topK]\n",
    "\n",
    "def stop_words(path):\n",
    "    with open(path, encoding='utf8') as f:\n",
    "        return [l.strip() for l in f]\n",
    "\n",
    "def main():\n",
    "    import glob\n",
    "    import random\n",
    "    import jieba\n",
    "    \n",
    "    files = glob.glob('./data/news/C000013/*.txt')\n",
    "    corpus = [get_content(x) for x in files]\n",
    "    \n",
    "    sample_inx = random.randint(0, len(corpus))\n",
    "    split_words = [x for x in jieba.cut(corpus[sample_inx]) if x not in stop_words('./data/stop_words.utf8')]\n",
    "    print('样本之一：' + corpus[sample_inx])\n",
    "    print('样本分词效果： '+ '/ '.join(split_words))\n",
    "    print('样本top10词： '+ str(get_TF(split_words)))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本之一：&nbsp;静脉曲张是一种常见病，多发病于长期站立或负重工作的人，其主要原因是由静脉壁薄弱，静脉瓣膜损坏及静脉内压增高所造成。爱护美腿　　也因为一些身体原因或是客观工作环境等影响造成。比如：先天性静脉壁薄弱、或者有相关家族史、身体肥胖或者从事长久站立的工作、长期服用口服避孕药，女性怀孕身体压力过大等。目前来看，无论用什么方法都不能完全治愈静脉曲张。小编提示：随着子宫一天天增大，孕妈咪的下腔静脉受到挤压，影响了血液回流，从而使静脉扩张，血液淤积在皮下的血管中。它和下肢浮肿同样发生在孕晚期，以下肢和外阴的静脉曲张最为明显。&gt;&gt;&gt;全文静脉曲张在发生之初，往往没有明显的症状。有人会觉得小腿皮肤痒、腿部肿胀、酸痛、疲劳、腿部沈重感，特别是在经期刚要来时最严重，尤其是站了一整天下来，小腿特别酸痛、脚踝肿胀，把脚抬高就比较舒服。&nbsp;　　当静脉曲张越严重，疼痛就越明显，甚至发生脚部血液淤积，脚踝变紫色，更严重者，血液不易回流会发生色素沈淀、湿疹样皮肤炎，并可能产生郁积性溃疡。有时静脉破裂会出血。&nbsp;　　有时也会沿著静脉壁产生血块发炎，即血栓性静脉炎，表皮会沿著静脉呈现红肿、疼痛的症状，甚至可摸出非常疼痛的结节。若血栓跑到肺脏，就有可能发生致死的肺栓塞症。因此静脉曲张的治疗多以为了减轻症状，同时也要注意生活预防：·要避免久站或久坐不动。如果工作性质如此，要注意每小时活动一次，促进血液循环。·每天多做几次抬腿操。肌肉收缩，帮助腿部静脉将肢体远端的血液送回心脏，因此抬腿有助于使血液回流，减缓静曲张。·穿弹性裤袜。这样能帮助血液进入较大且较深处的静脉。·适当垫高床尾。睡觉的时候，把腿部抬高5-10厘米，有助于睡眠时的血液回流。·降低鞋后跟的高度。鞋跟过高，更多地增加脚趾的压力，阻碍回血。·保持理想体重。身体过于肥胖，增加了下肢的负担。·避免紧身衣物。以免使血液聚积在腿部。·小心服用避孕药。避孕药中的一些成分使血液的粘稠度过高，使血液流动缓慢，影响回流。·不抽烟；吸烟使血管收缩，回流缓慢。小编提示：长期保持腿部在一非常好的状态下，是预防腿部静脉曲张的重要事项。时刻注意保护您的腿，不使其有肿胀之情形，并注意以下12招&gt;&gt;&gt;&gt;全文点击进入下一页&gt;&gt;静脉曲张的常用治疗方法静脉曲张的常用治疗方法：治疗方法除要适当运动外，要避免久站或久坐不动，至少每小时要活动一下，促进血液循环，必要时可选用下列方法：压迫治疗法：穿弹性袜或利用弹性绷带包扎压迫以减少静脉逆流及郁血现象。购买医用弹性袜要特别注意合身性，美国曾有统计，有三分之一的静脉曲张患者所穿的弹性袜并不合身，所以不但没效，也不舒服。最好早晨一起床就马上穿，晚上睡觉时不必穿。硬化剂治疗：把硬化剂打入静脉内，破坏内皮细胞，引起血管痉挛、发炎反应而形成血栓、纤维化，而达成消除静脉曲张的目的。最适合用在细小静脉扩张。副作用包括过敏、局部疼痛、皮肤坏死及色素沈著等。若不慎将硬化剂打入动脉内可造成肢端坏死及截肢的后果。手术治疗：目的在去除曲张的静脉，手术方法包括：大隐静脉高位结扎、静脉剥除法、穿孔静脉结扎或单纯静脉切除法。并非所有静脉曲张皆要手术切除，手术前一定要确认深部静脉是通畅的。下列病人可以手术治疗：&nbsp;　　酸痛肿胀等症状严重，难以忍受。再发血栓静脉炎。祛血管破裂出血。血液郁积造成并发症如皮肤炎、溃疡。手术后短期内仍要以弹性绷带包扎或穿著弹性袜。术後仍有静脉曲张复发机会。所以容易发生静脉曲张的人要注意预防，就是要避免久站或久坐不动（无法避免者，可穿弹性袜），要有适当的运动。2&nbsp;&nbsp;&nbsp;\n",
      "样本分词效果：nbsp/eng 静脉曲张/l 一种/m 常见病/nr 多发病/n 长期/d 站立/v 负重/v 工作/vn 主要/b 原因/n 静脉/n 壁/n 薄弱/a 静脉/n 瓣膜/n 损坏/v 静脉/n 内压/n 增高/v 造成/v 爱护/v 美腿/nz 　/x 　/x 身体/n 原因/n 客观/n 工作/vn 环境/n 影响/vn 造成/v 先天性/n 静脉/n 壁/n 薄弱/a 相关/v 家族史/n 身体/n 肥胖/a 从事/v 长久/d 站立/v 工作/vn 长期/d 服用/vn 口服/n 避孕药/n 女性/n 怀孕/v 身体/n 压力/n 目前/t 来看/u 方法/n 不能/v 完全/ad 治愈/v 静脉曲张/l 编/n 提示/v 子宫/nr 一天天/m 增大/v 孕妈咪/n 下腔/n 静脉/n 挤压/v 影响/vn 血液/n 回流/v 静脉/n 扩张/v 血液/n 淤积/n 皮下/n 血管/n 中/f 下肢/n 浮肿/n 同样/d 发生/v 孕晚期/t 下肢/n 外阴/n 静脉曲张/l 最为/d 明显/a gt/eng gt/eng gt/eng 全文/n 静脉曲张/l 发生/v 初/f 往往/t 没有/v 明显/a 症状/n 有人/r 会/v 觉得/v 小腿/n 皮肤痒/n 腿部/n 肿胀/v 酸痛/n 疲劳/a 腿部/n 沈重感/nr 特别/d 经期/n 刚/d 来时/t 严重/a 尤其/d 站/v 一整天/m 下来/t 小腿/n 特别/d 酸痛/n 脚踝/n 肿胀/v 脚/n 抬高/v 比较/d 舒服/a nbsp/eng 　/x 　/x 静脉曲张/l 越/d 严重/a 疼痛/n 越/d 明显/a 发生/v 脚部/f 血液/n 淤积/n 脚踝/n 变/v 紫色/n 更/d 严重者/nr 血液/n 不易/a 回流/v 会/v 发生/v 色素/n 沈淀/ns 湿疹/n 样/n 皮肤/n 炎/n 可能/v 产生/n 郁积/n 性溃疡/n 静脉/n 破裂/v 会/v 出血/v nbsp/eng 　/x 　/x 会/v 沿著/v 静脉/n 壁/n 产生/n 血块/n 发炎/n 血栓性/n 静脉炎/nr 表皮/n 会/v 沿著/v 静脉/n 呈现/v 红肿/n 疼痛/n 症状/n 可摸/v 出/v 非常/d 疼痛/n 结节/n 血栓/n 跑/v 肺脏/n 可能/v 发生/v 致死/v 肺栓塞/n 症/zg 静脉曲张/l 治疗/v 减轻/v 症状/n 注意/v 生活/vn 预防/v ·/x 避免/v 久/a 站/v 久坐/v 动/v 工作/vn 性质/n 注意/v 小时/n 活动/vn 一次/m 促进/v 血液循环/n ·/x 每天/r 做/v 几次/m 抬腿/v 操/v 肌肉/n 收缩/v 帮助/v 腿部/n 静脉/n 肢体/n 远/a 端的/z 血液/n 送回/v 心脏/n 抬腿/v 有助于/v 血液/n 回流/v 减缓/v 静/nr 曲张/a ·/x 穿/zg 弹性/n 裤袜/n 帮助/v 血液/n 进入/v 较大/a 深处/s 静脉/n ·/x 适当/a 垫高/v 床尾/n 睡觉/v 腿部/n 抬高/v 10/m 厘米/q 有助于/v 睡眠/v 时/ng 血液/n 回流/v ·/x 降低/v 鞋后跟/n 高度/n 鞋跟/n 高/a 更多/d 增加/v 脚趾/n 压力/n 阻碍/v 回血/v ·/x 保持/v 理想/n 体重/n 身体/n 过于/v 肥胖/a 增加/v 下肢/n 负担/v ·/x 避免/v 紧身衣/i 物/zg 血液/n 聚积/n 腿部/n ·/x 小心/n 服用/vn 避孕药/n 避孕药/n 中/f 成分/n 血液/n 粘稠度/n 高/a 血液/n 流动/vn 缓慢/d 影响/vn 回流/v ·/x 抽烟/v 吸烟/v 血管/n 收缩/v 回流/v 缓慢/d 编/n 提示/v 长期保持/n 腿部/n 非常/d 状态/n 预防/v 腿部/n 静脉曲张/l 重要/a 事项/n 时刻/n 注意/v 保护/v 腿/n 不使/c 肿胀/v 情形/n 注意/v 以下/f 12/m 招/v gt/eng gt/eng gt/eng gt/eng 全文/n 点击/v 进入/v 一页/m gt/eng gt/eng 静脉曲张/l 常用/b 治疗/v 方法/n 静脉曲张/l 常用/b 治疗/v 方法/n 治疗/v 方法/n 除要/c 适当/a 运动/vn 外/f 避免/v 久/a 站/v 久坐/v 动/v 至少/d 小时/n 活动/vn 一下/m 促进/v 血液循环/n 必要/d 时/ng 选用/v 下列/v 方法/n 压迫/v 治疗法/n 穿/zg 弹性/n 袜/ng 利用/n 弹性/n 绷带/n 包扎/v 压迫/v 减少/v 静脉/n 逆流/n 郁血/n 现象/n 购买/v 医用/n 弹性/n 袜/ng 特别/d 注意/v 合身/v 性/n 美国/ns 统计/v 三分之一/mq 静脉曲张/l 患者/n 所穿/v 弹性/n 袜/ng 不合身/n 没效/v 舒服/a 最好/a 早晨/t 起床/v 马上/d 穿/zg 晚上/t 睡觉时/n 不必/d 穿/zg 硬化剂/n 治疗/v 硬化剂/n 打入/v 静脉/n 破坏/v 内皮细胞/n 引起/v 血管/n 痉挛/vn 发炎/n 反应/vn 形成/v 血栓/n 纤维化/n 达成/v 消除/v 静脉曲张/l 目的/n 适合/v 细小/n 静脉/n 扩张/v 副作用/n 包括/v 过敏/nr 局部/n 疼痛/n 皮肤/n 坏死/v 色素/n 沈著/nr 若不慎/i 硬化剂/n 打入/v 动脉/n 造成/v 肢端/n 坏死/v 截肢/n 后果/n 手术/n 治疗/v 目的/n 去除/v 曲张/a 静脉/n 手术/n 方法/n 包括/v 隐/n 静脉/n 高位/n 结扎/v 静脉/n 剥除/v 法/j 穿孔/n 静脉/n 结扎/v 单纯/a 静脉/n 切除/v 法/j 静脉曲张/l 皆/d 手术/n 切除/v 手术/n 前/f 一定/d 确认/v 深部/j 静脉/n 通畅/a 下列/v 病人/n 手术/n 治疗/v nbsp/eng 　/x 　/x 酸痛/n 肿胀/v 症状/n 严重/a 难以忍受/l 发/v 血栓/n 静脉炎/nr 祛/v 血管/n 破裂/v 出血/v 血液/n 郁积/n 造成/v 并发症/l 皮肤/n 炎/n 溃疡/n 手术/n 短期内/n 仍要/d 弹性/n 绷带/n 包扎/v 穿著/n 弹性/n 袜/n 术/v 後/nr 静脉曲张/l 复发/v 机会/n 容易/a 发生/v 静脉曲张/l 注意/v 预防/v 避免/v 久/a 站/v 久坐/v 动/v 无法/n 避免/v 穿/zg 弹性/n 袜/n 适当/a 运动/vn nbsp/eng nbsp/eng nbsp/eng\n",
      "样本的topK（10）词：[('静脉/n', 20), ('静脉曲张/l', 14), ('血液/n', 12), ('gt/eng', 9), ('·/x', 9), ('\\u3000/x', 8), ('弹性/n', 8), ('nbsp/eng', 7), ('腿部/n', 7), ('治疗/v', 7)]\n"
     ]
    }
   ],
   "source": [
    "#jieba词性标注示例\n",
    "def main():\n",
    "    import glob\n",
    "    import random\n",
    "    import jieba\n",
    "    import jieba.posseg as psg\n",
    "    \n",
    "    files = glob.glob('./data/news/C000013/*.txt')\n",
    "    corpus = [get_content(x) for x in files]\n",
    "    \n",
    "    sample_inx = random.randint(0, len(corpus))\n",
    "    \n",
    "    split_words = [w+'/'+t for w, t in psg.cut(corpus[sample_inx])\n",
    "                  if w not in stop_words('./data/stop_words.utf8')]\n",
    "    print('样本之一：'+corpus[sample_inx])\n",
    "    print('样本分词效果：' + ' '.join(split_words))\n",
    "    print('样本的topK（10）词：' + str(get_TF(split_words)))\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
